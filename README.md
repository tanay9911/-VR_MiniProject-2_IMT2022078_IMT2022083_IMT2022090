# BLIP VQA Inference

This repository contains a script for running inference using a BLIP (Bootstrapping Language-Image Pretraining) model fine-tuned for Visual Question Answering (VQA).

---

## ğŸ› ï¸ Setup

### 1. Install Required Libraries

Make sure you have Python 3.7 or higher. Then install all necessary dependencies using:

```bash
pip install -r requirements.txt

